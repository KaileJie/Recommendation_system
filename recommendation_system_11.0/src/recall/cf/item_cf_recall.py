# src/recall/cf/item_cf_recall.py

import os
import logging
import pandas as pd

from src.utils.weight_utils import get_time_weight
from src.recall.cf.dataset_cf import load_cf_behavior_df, load_valid_item_ids
from src.recall.cf.build_cf_matrix import build_user_item_matrix
from src.recall.cf.compute_similarity import compute_item_sim_matrix
from src.recall.cf.batch_recommend import recommend_for_users_batch
from src.data.load_behavior_log import ensure_outdir

# ----------- Config -----------
INPUT_BEHAVIOR_CSV = "data/raw/user_behavior_log_info.csv"
ITEM_METADATA_CSV = "data/raw/item_metadata.csv"
OUTDIR = "output/item_cf/"
TRAIN_WINDOW_DAYS = 30   # âš ï¸ æ–°å¢: è®­ç»ƒçª—å£
CUTOFF_DAYS = 7          # âš ï¸ æ–°å¢: ç•™å‡ºæœ€å7å¤©åšè¯„ä¼°
CHUNKSIZE = 50000
TOP_K = 20
MIN_SIM = 0.1
BLOCK_SIZE = 500
MAX_USERS = None

# ----------- Logging Setup -----------
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

def main():
    logger.info("ğŸš€ Starting Item-based CF recall pipeline")

    # 1. åŠ è½½åˆæ³• item id
    valid_item_ids = load_valid_item_ids(ITEM_METADATA_CSV)

    # 2. åŠ è½½å¹¶æ¸…æ´—è¡Œä¸ºæ•°æ®
    behavior_df = load_cf_behavior_df(
        behavior_csv=INPUT_BEHAVIOR_CSV,
        days_window=TRAIN_WINDOW_DAYS,
        valid_item_ids=valid_item_ids,
        chunksize=CHUNKSIZE
    )

    # âš ï¸ æ–°å¢: å»æ‰æœ€å7å¤©çš„æ•°æ®ï¼Œä¿è¯è®­ç»ƒå’Œè¯„ä¼°ä¸é‡å 
    cutoff_dt = behavior_df["dt"].max() - pd.Timedelta(days=CUTOFF_DAYS)
    behavior_df = behavior_df[behavior_df["dt"] < cutoff_dt].copy()
    logger.info(f"âš ï¸ Training cutoff applied: using data < {cutoff_dt}")


    if behavior_df.empty:
        logger.error("âŒ No valid behavior data found.")
        return

    # âœ… å¿«é€Ÿæµ‹è¯•æ¨¡å¼é™åˆ¶ç”¨æˆ·æ•°é‡
    if MAX_USERS is not None:
        top_users = behavior_df["user_id"].unique()[:MAX_USERS]
        behavior_df = behavior_df[behavior_df["user_id"].isin(top_users)]
        logger.info(f"ğŸ§ª Quick test mode: restricted to {len(top_users)} users")

    # 3. æ„å»ºç”¨æˆ·-ç‰©å“çŸ©é˜µï¼ˆå†…éƒ¨è‡ªåŠ¨åŠ æƒï¼‰
    ref_date = behavior_df["dt"].max()
    UI, u2idx, i2idx = build_user_item_matrix(
        df=behavior_df,
        ref_date=ref_date,
        time_weight_method="exp",
        decay_days=TRAIN_WINDOW_DAYS,
        min_weight=0.1,
        return_mappings=True,
        strict=True
    )

    # åè½¬ item æ˜ å°„è¡¨ï¼ˆç”¨æˆ·æ˜ å°„å·²ç»åœ¨ recommend_for_users_batch å†…éƒ¨å¤„ç†ï¼‰
    idx2it = {v: k for k, v in i2idx.items()}

    # 4. è®¡ç®— item-item ç›¸ä¼¼åº¦
    S = compute_item_sim_matrix(UI, min_sim=MIN_SIM, block_size=BLOCK_SIZE)

    # 5. æ¨èå¬å›
    all_users = [u for u in u2idx if UI[u2idx[u]].getnnz() > 0]
    logger.info(f"ğŸ¯ Performing recall for {len(all_users)} users...")

    recs_df = recommend_for_users_batch(
        UI, S, u2idx, idx2it,
        user_ids=all_users,
        n_recs=TOP_K,
        batch_size=512,
        filter_seen=True,
        min_score=None,
        as_dataframe=True,
        source_tag="itemcf"
    )

    # 6. ä¿å­˜ç»“æœ
    ensure_outdir(OUTDIR)
    output_path = os.path.join(OUTDIR, "itemcf_recall.csv")
    recs_df.to_csv(output_path, index=False)

    # æ‰“å°çŸ©é˜µç¨€ç–ä¿¡æ¯
    logger.info("ğŸ“Š Matrix stats:")
    logger.info(f"  ğŸ”¸ User-Item matrix shape: {UI.shape}, non-zero entries: {UI.nnz}")
    logger.info(f"  ğŸ”¸ Item-Item similarity matrix shape: {S.shape}, non-zero entries: {S.nnz}")

    logger.info(f"âœ… Recommendation results saved to: {output_path}")


if __name__ == "__main__":
    main()
