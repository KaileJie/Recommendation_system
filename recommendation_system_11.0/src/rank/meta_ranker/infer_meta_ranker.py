# src/rank/meta_ranker/infer_meta_ranker.py

import os
import json
import pickle
import logging
import pandas as pd
import numpy as np
import lightgbm as lgb
import joblib

# -------- Logger --------
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# -------- Config --------
OUTPUT_DIR = "output/meta_ranker"
os.makedirs(OUTPUT_DIR, exist_ok=True)

TRAIN_DATA_PATH = os.path.join(OUTPUT_DIR, "training_data.json")
GBDT_MODEL_PATH = os.path.join(OUTPUT_DIR, "gbdt_model.pkl")
LR_MODEL_PATH = os.path.join(OUTPUT_DIR, "lr_model.pkl")
ENCODER_PATH = os.path.join(OUTPUT_DIR, "onehot_encoder.pkl")

INFER_OUTPUT_PATH = os.path.join(OUTPUT_DIR, "meta_ranker_infer.json")
TOP_K = 20


def load_training_data():
    """åŠ è½½å’Œ build_training_data ç›¸åŒç»“æ„çš„æ•°æ®"""
    records = []
    with open(TRAIN_DATA_PATH, "r") as f:
        for line in f:
            records.append(json.loads(line))

    df = pd.DataFrame([{
        "user_id": r["user_id"],
        "item_id": r["item_id"],
        "label": r["label"],
        "score_itemcf": r["scores"]["itemcf"],
        "score_keyword": r["scores"]["keyword"],
        "score_dnn": r["scores"]["youtube_dnn"],
        **r["features"]
    } for r in records])

    return df


def load_models():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    try:
        gbm = joblib.load(GBDT_MODEL_PATH)
        lr = joblib.load(LR_MODEL_PATH)
        enc = joblib.load(ENCODER_PATH)
        logger.info("âœ… Models loaded successfully")
        return gbm, lr, enc
    except FileNotFoundError as e:
        logger.error(f"âŒ Model file not found: {e}")
        raise
    except Exception as e:
        logger.error(f"âŒ Error loading models: {e}")
        raise


def validate_input_data(df):
    """éªŒè¯è¾“å…¥æ•°æ®çš„å®Œæ•´æ€§"""
    required_cols = ["user_id", "item_id", "score_itemcf", "score_keyword", "score_dnn"]
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        raise ValueError(f"âŒ Missing required columns: {missing_cols}")
    
    if df.empty:
        raise ValueError("âŒ Input data is empty")
    
    logger.info(f"âœ… Input data validated: {df.shape[0]} samples, {df['user_id'].nunique()} users")


def infer_from_recall_data(recall_data_path, user_profile_path, top_k=20):
    """
    ä»æ–°çš„å¬å›ç»“æœè¿›è¡Œæ¨ç†
    
    Args:
        recall_data_path: å¬å›ç»“æœæ–‡ä»¶è·¯å¾„
        user_profile_path: ç”¨æˆ·ç”»åƒæ–‡ä»¶è·¯å¾„
        top_k: è¿”å›çš„æ¨èæ•°é‡
    """
    logger.info(f"ğŸš€ Running inference from recall data: {recall_data_path}")
    
    try:
        # 1. åŠ è½½å¬å›ç»“æœ
        recall_df = pd.read_csv(recall_data_path)
        logger.info(f"âœ… Loaded recall data: {recall_df.shape}")
        
        # 2. åŠ è½½ç”¨æˆ·ç”»åƒ
        from src.data.load_user_profile import load_user_profile_feature
        profile_df = load_user_profile_feature(user_profile_path)
        logger.info(f"âœ… Loaded user profile: {profile_df.shape}")
        
        # 3. åˆå¹¶æ•°æ®
        merged_df = recall_df.merge(profile_df, on="user_id", how="left")
        
        # 4. å¤„ç†ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç­–ç•¥ï¼‰
        from src.rank.meta_ranker.build_training_data import handle_missing_features
        merged_df = handle_missing_features(merged_df)
        
        # 5. åŠ è½½æ¨¡å‹
        gbm, lr, enc = load_models()
        
        # 6. å‡†å¤‡ç‰¹å¾
        feature_cols = [c for c in merged_df.columns if c not in ["user_id", "item_id"]]
        X = merged_df[feature_cols]
        
        # 7. é¢„æµ‹
        leaf_idx = gbm.predict(X, pred_leaf=True)
        leaf_idx = np.array(leaf_idx, dtype=np.int32)
        X_enc = enc.transform(leaf_idx)
        final_scores = lr.predict_proba(X_enc)[:, 1]
        
        # 8. ç”Ÿæˆæ¨èç»“æœ
        results = []
        for row, score in zip(merged_df.itertuples(index=False), final_scores):
            record = {
                "user_id": row.user_id,
                "item_id": row.item_id,
                "final_score": float(score),
                "scores": {
                    "itemcf": float(getattr(row, 'score_itemcf', 0.0)),
                    "keyword": float(getattr(row, 'score_keyword', 0.0)),
                    "youtube_dnn": float(getattr(row, 'score_dnn', 0.0))
                }
            }
            results.append(record)
        
        # 9. æŒ‰ç”¨æˆ·åˆ†ç»„æ’åº
        output = []
        df_results = pd.DataFrame(results)
        for uid, group in df_results.groupby("user_id"):
            top_items = group.sort_values("final_score", ascending=False).head(top_k)
            output.extend(top_items.to_dict(orient="records"))
        
        logger.info(f"ğŸ“Š Generated {len(output)} recommendations for {df_results['user_id'].nunique()} users")
        return output
        
    except Exception as e:
        logger.error(f"âŒ Inference from recall data failed: {e}")
        raise


def main():
    logger.info("ğŸš€ Running inference with Meta-Ranker (GBDT+LR)")

    try:
        # 1. åŠ è½½è®­ç»ƒæ•°æ®ç»“æ„ï¼ˆåªæ˜¯ä¸ºäº†è·å–ç‰¹å¾åˆ—ç»“æ„ï¼‰
        # æ³¨æ„ï¼šå®é™…æ¨ç†æ—¶åº”è¯¥ä½¿ç”¨æ–°çš„å¬å›ç»“æœï¼Œè¿™é‡Œä»…ç”¨äºæ¼”ç¤º
        df = load_training_data()
        feature_cols = [c for c in df.columns if c not in ["user_id", "item_id", "label"]]
        
        # éªŒè¯è¾“å…¥æ•°æ®
        validate_input_data(df)

        # 2. åŠ è½½æ¨¡å‹
        gbm, lr, enc = load_models()

        # 3. æ„é€ æ¨ç†æ•°æ®
        X = df[feature_cols]

        # 4. GBDT å¶å­ç´¢å¼• â†’ One-hot
        leaf_idx = gbm.predict(X, pred_leaf=True)
        leaf_idx = np.array(leaf_idx, dtype=np.int32)
        X_enc = enc.transform(leaf_idx)

        # 5. LR è¾“å‡ºæœ€ç»ˆåˆ†æ•°
        final_scores = lr.predict_proba(X_enc)[:, 1]

        # 6. ç»„è£… JSON è¾“å‡º
        results = []
        for row, score in zip(df.itertuples(index=False), final_scores):
            record = {
                "user_id": row.user_id,
                "item_id": row.item_id,
                "final_score": float(score),
                "scores": {
                    "itemcf": float(row.score_itemcf),
                    "keyword": float(row.score_keyword),
                    "youtube_dnn": float(row.score_dnn)
                },
                "features": {
                    "age_range": row.age_range,
                    "gender": row.gender,
                    "city": row.city,
                    "cluster_id": row.cluster_id,
                    "recency": row.recency,
                    "frequency": row.frequency,
                    "actions_per_active_day_30d": row.actions_per_active_day_30d,
                    "monetary": row.monetary,
                    "rfm_score": row.rfm_score
                }
            }
            results.append(record)

        # æŒ‰ user_id åˆ†ç»„ + æ’åºå– Top-K
        output = []
        df_results = pd.DataFrame(results)
        for uid, group in df_results.groupby("user_id"):
            top_items = group.sort_values("final_score", ascending=False).head(TOP_K)
            output.extend(top_items.to_dict(orient="records"))

        # ä¿å­˜ JSON
        with open(INFER_OUTPUT_PATH, "w") as f:
            for r in output:
                f.write(json.dumps(r) + "\n")

        logger.info(f"ğŸ“¦ Inference results saved to {INFER_OUTPUT_PATH}")
        logger.info(f"ğŸ“Š Processed {len(output)} recommendations for {df_results['user_id'].nunique()} users")

    except Exception as e:
        logger.error(f"âŒ Inference failed: {e}")
        raise


if __name__ == "__main__":
    main()
